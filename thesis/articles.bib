@inproceedings{Gibson2010,
   abstract = {Chip Multiprocessors (CMPs) are now commodity hardware, but commoditization of parallel software remains elusive. In the near term, the current trend of increased coreper-socket count will continue, despite a lack of parallel software to exercise the hardware. Future CMPs must deliver thread-level parallelism when software provides threads to run, but must also continue to deliver performance gains for single threads by exploiting instructionlevel parallelism and memory-level parallelism. However, power limitations will prevent conventional cores from exploiting both simultaneously. This work presents the Forwardflow Architecture, which can scale its execution logic up to run single threads, or down to run multiple threads in a CMP. Forwardflow dynamically builds an explicit internal dataflow representation from a conventional instruction set architecture, using forward dependence pointers to guide instruction wakeup, selection, and issue. Forwardflow's backend is organized into discrete units that can be individually (de-)activated, allowing each core's performance to be scaled by system software at the architectural level. On single threads, Forwardflow core scaling yields a mean runtime reduction of 21% for a 37% increase in power consumption. For multithreaded workloads, a Forwardflowbased CMP allows system software to select the performance point that best matches available power. Copyright 2010 ACM.},
   author = {Dan Gibson and David A. Wood},
   city = {New York, New York, USA},
   doi = {10.1145/1815961.1815966},
   isbn = {9781450300520},
   issn = {10636897},
   journal = {Proceedings - International Symposium on Computer Architecture},
   keywords = {Chip Multiprocessor (CMP),Power,Scalable core},
   pages = {14-25},
   publisher = {ACM Press},
   title = {Forwardflow: A scalable core for power-constrained CMPs},
   url = {http://portal.acm.org/citation.cfm?doid=1815961.1815966},
   year = {2010},
}
@report{,
   abstract = {The doubling of microprocessor performance every three years has been the result of two factors: more transistors per chip and superlinear scaling of the processor clock with technology generation. Our results show that, due to both diminishing improvements in clock rates and poor wire scaling as semiconductor devices shrink, the achievable performance growth of conventional microarchitectures will slow substantially. In this paper, we describe technology-driven models for wire capacitance, wire delay, and microarchitectural component delay. Using the results of these models, we measure the simulated performance-estimating both clock rate and IPC-of an aggressive out-of-order microarchitecture as it is scaled from a 250nm technology to a 35nm technology. We perform this analysis for three clock scaling targets and two microarchitecture scaling strategies: pipeline scaling and capacity scaling. We find that no scaling strategy permits annual performance improvements of better than 12.5%, which is far worse than the annual 50-60% to which we have grown accustomed.},
   author = {Vikas Agarwal and £ M S Hrishikesh and Stephen W Keckler and Doug Burger},
   title = {Clock Rate versus IPC: The End of the Road for Conventional Microarchitectures},
   url = {www.cs.utexas.edu/users/cart},
}
@article{,
   title = {2018_ISCA_Division_of_Labor_A_More_Effective_Approach_to_Prefetching},
}
@report{Reinman1999,
   abstract = {In the pursuit of instruction-level parallelism, significant demands are placed on a processor's instruction delivery mechanism. Delivering the performance necessary to meet future processor execution targets requires that the performance of the instruction delivery mechanism scale with the execution core. Attaining these targets is a challenging task due to I-cache misses, branch mispredictions, and taken branches in the instruction stream. To further complicate matters, a VLSI interconnect scaling trend is materializing that further limits the performance of front-end designs in future generation process technologies. To counter these challenges, we present a fetch architecture that permits a faster cycle time than previous designs and scales better with future process technologies. Our design , called the Fetch Target Buffer, is a multi-level fetch block-oriented predictor. We decouple the FTB from the instruction fetch and decode pipelines to afford it the fastest clock possible. Through cycle-based simulation and circuit-level delay analysis, we find that our multi-level FTB design is capable of delivering instructions 25% faster than the best single-level BTB-based pipeline configuration. Moreover, we show that our design scales better to future process technologies than traditional single-level designs.},
   author = {Glenn Reinman and Todd Austin and Brad Calder},
   title = {A Scalable Front-End Architecture for Fast Instruction Delivery},
   year = {1999},
}
@book{,
   abstract = {Includes index.},
   author = {Sigarch. and IEEE Computer Society. Technical Committee on Computer Architecture.},
   isbn = {9781479943944},
   pages = {554},
   publisher = {IEEE Press},
   title = {ISCA 2014 : the 41st annual International Symposium on Computer Architecuture : conference proceedings : June 14-18, 2014, Minneapolis, MN, USA},
   year = {2014},
}
@article{Asheim2021,
   abstract = {Many contemporary applications feature multi-megabyte instruction footprints that overwhelm the capacity of branch target buffers (BTB) and instruction caches (L1-I), causing frequent front-end stalls that inevitably hurt performance. BTB is crucial for performance as it enables the front-end to accurately resolve the upcoming execution path and steer instruction fetch appropriately. Moreover, it also enables highly effective fetch-directed instruction prefetching that can eliminate many L1-I misses. For these reasons, commercial processors allocate vast amounts of storage capacity to BTBs. This letter aims to reduce BTB storage requirements by optimizing the organization of BTB entries. Our key insight is that today's BTBs store the full target address for each branch, yet the vast majority of dynamic branches have short offsets requiring just a handful of bits to encode. Based on this insight, we organize the BTB as an ensemble of smaller BTBs, each storing offsets within a particular range. Doing so enables a dramatic reduction in storage for target addresses. We also compress tags to reduce the tag storage cost. Our final design, called BTB-X, uses an ensemble of five BTBs with compressed tags that enables it to track 2.8x more branches than a conventional BTB with the same storage budget.},
   author = {Truls Asheim and Boris Grot and Rakesh Kumar},
   doi = {10.1109/LCA.2021.3109945},
   issn = {15566064},
   issue = {2},
   journal = {IEEE Computer Architecture Letters},
   keywords = {Server,branch target buffer (BTB),instruction cache,microarchitecture,prefeteching},
   pages = {134-137},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {BTB-X: A Storage-Effective BTB Organization},
   volume = {20},
   year = {2021},
}
@report{Sherwood2002,
   abstract = {Understanding program behavior is at the foundation of computer architecture and program optimization. Many programs have wildly different behavior on even the very largest of scales (over the complete execution of the program). This realization has ramifications for many architectural and compiler techniques, from thread scheduling, to feedback directed optimizations, to the way programs are simulated. However, in order to take advantage of time-varying behavior, we must first develop the analytical tools necessary to automatically and efficiently analyze program behavior over large sections of execution. Our goal is to develop automatic techniques that are capable of finding and exploiting the Large Scale Behavior of programs (behavior seen over billions of instructions). The first step towards this goal is the development of a hardware independent metric that can concisely summarize the behavior of an arbitrary section of execution in a program. To this end we examine the use of Basic Block Vectors. We quantify the effectiveness of Basic Block Vectors in capturing program behavior across several different architectural met-rics, explore the large scale behavior of several programs, and develop a set of algorithms based on clustering capable of analyzing this behavior. We then demonstrate an application of this technology to automatically determine where to simulate for a program to help guide computer architecture research.},
   author = {Timothy Sherwood and Erez Perelman and Greg Hamerly and Brad Calder},
   title = {Automatically Characterizing Large Scale Program Behavior},
   url = {http://www.simplescalar.com/.},
   year = {2002},
}
@article{Perleberg1993,
   abstract = {A Branch Target Buffer (BTB) can reduce the performance penalty of branches in pipelined processors by predicting the path of the branch and caching information used by the branch. This paper discusses two major issues in the desigin of BTB’s, with the goal of achieving maximum performance with a limited number of bits allocated to the BTB implementation First is the issue of BTB management—when to enter and discan branches from the BTB. Higher performance can be obtained by entering branches into the BTB only when they experience i branch taken execution. A new method for discarding branche; from the BTB is examined. This method discards the brand with the smallest expected value for improving performance outperforming the LRU strategy by a small margin, at the cos of additional complexity. The second major issue discussed is the question of what information to store in the BTB. A BTB entry can consist of one or more of the following: branch tag (i.e., the branch instruction address), prediction information, the branch target address, and instructions at the branch target. A variety of BTB designs, with one or more of these fields, are evaluated and compared. This study is then extended to multilevel BTB’s, in which different levels in the BTB have different amounts of information per entry. For the specific implementation assumptions used, multilevel BTB’s improved performance over single level BTB’s only slightly, also at the cost of additional complexity. Multilevel BTB’s may, however, provide significant performance improvements for other machines implementations. Design target miss ratios for BTB’s are developed, so that the performance of BTB’s for real workloads may be estimated. © 1993 IEEE},
   author = {Chris H. Perleberg and Alan Jay Smith},
   doi = {10.1109/12.214687},
   issn = {00189340},
   issue = {4},
   journal = {IEEE Transactions on Computers},
   keywords = {Branch,CPU design,CPU performance evaluation,branch problem,branch target buffer,cache memory,pipeline,pipelining},
   pages = {396-412},
   title = {Branch Target Buffer Design and Optimization},
   volume = {42},
   year = {1993},
}
@report{,
   author = {Premkishore Shivakumar and Norman P Jouppi},
   title = {CACTI 3.0: An Integrated Cache Timing, Power, and Area Model},
   url = {http://www.research.compaq.com/wrl/},
}
@article{Sharafeddine2012,
   abstract = {High-performance superscalar architectures used to exploit instruction level parallelism in single-thread applications have become too complex and power hungry for the multicore processors era. We propose a new architecture that uses multiple small latency-tolerant out-of-order cores to improve single-thread performance. Improving single-thread performance with multiple small out-of-order cores allows designers to place more of these cores on the same die. Consequently, emerging highly parallel applications can take full advantage of the multicore parallel hardware without sacrificing performance of inherently serial and hard to parallelize applications. Our architecture combines speculative multithreading (SpMT) with checkpoint recovery and continual flow pipeline architectures. It splits single-thread program execution into disjoint control and data threads that execute concurrently on multiple cooperating small and latency-tolerant out-oforder cores. Hence we call this style of execution Disjoint Out-of-Order Execution (DOE). DOE uses latency tolerance to overcome performance issues of SpMT caused by interthread data dependences. To evaluate this architecture, we have developed a microarchitecture performance model of DOE based on PTLSim, a simulation infrastructure of the x86 instruction set architecture. We evaluate the potential performance of DOE processor architecture using a simple heuristic to fork control independent threads in hardware at the target addresses of future procedure return instructions. Using applications from SpecInt 2000, we study DOE under ideal as well as realistic architectural constraints. We discuss the performance impact of key DOE architecture and application variables such as number of cores, interthread data dependences, intercore data communication delay, buffers capacity, and branch mispredictions. Without any DOE specific compiler optimizations, our results show that DOE outperforms conventional SpMT architectures by 15%, on average. We also show that DOE with four small cores can perform on average equally well to a large superscalar core, consuming about the same power. Most importantly, DOE improves throughput performance by a significant amount over a large superscalar core, up to 2.5 times, when running multitasking applications. © 2012 ACM.},
   author = {Mageda Sharafeddine and Komal Jothi and Haitham Akkary},
   doi = {10.1145/2355585.2355592},
   issn = {15443566},
   issue = {3},
   journal = {Transactions on Architecture and Code Optimization},
   month = {9},
   title = {Disjoint out-of-order execution processor},
   volume = {9},
   year = {2012},
}
@inproceedings{Ansari2020,
   abstract = {The frontend stalls caused by instruction and BTB misses are a significant source of performance degradation in server processors. Prefetchers are commonly employed to mitigate frontend bottleneck. However, next-line prefetchers, which are available in server processors, are incapable of eliminating a considerable number of L1 instruction misses. Temporal instruction prefetchers, on the other hand, effectively remove most of the instruction and BTB misses but impose significant area overhead. Recently, an old idea of using BTB-directed instruction prefetching is revived to address the limitations of temporal instruction prefetchers. While this approach leads to prefetchers with low area overhead, it requires significant changes to the frontend of a processor. Moreover, as this approach relies on the BTB content for prefetching, BTB misses stall the prefetcher, and likely lead to costly instruction misses. Especially as instruction misses are usually more expensive than BTB misses, the dependence of instruction prefetching to the BTB content is harmful to workloads with very large instruction footprints. Moreover, BTB-directed instruction prefetchers, as proposed in prior work, cannot be applied to variable-length ISAs. In this work, we showcase the harmful effects of making instruction prefetchers depend on the BTB content. Moreover, we divide the frontend bottleneck into three categories and use a divide-and-conquer approach to propose simple and effective solutions for each one. Sequential misses can be covered by an accurate and timely sequential prefetcher named SN4L, a lightweight discontinuity prefetcher named Dis eliminates discontinuity misses, and the BTB misses are reduced by pre-decoding the prefetched blocks. We also discuss how our proposal can be used for variable-length ISAs with low storage overhead. Our proposal, SN4L+ Dis+BTB, imposes the same area overhead as the state-of-the-art BTB-directed prefetcher, and at the same time, outperforms it by 5% on average and up to 16%.},
   author = {Ali Ansari and Pejman Lotfi-Kamran and Hamid Sarbazi-Azad},
   doi = {10.1109/ISCA45697.2020.00017},
   isbn = {9781728146614},
   issn = {10636897},
   journal = {Proceedings - International Symposium on Computer Architecture},
   keywords = {Frontend bottleneck,divide and conquer,instruction and BTB prefetching},
   month = {5},
   pages = {65-78},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Divide and Conquer Frontend Bottleneck},
   volume = {2020-May},
   year = {2020},
}
@report{,
   abstract = {The ITTAGE, Indirect Target TAgged GEometric length predictor, was introduced in [5] at the same time as the TAGE conditional branch predictor. ITTAGE relies on the same principles as the TAGE predictor several predictor tables indexed through independent functions of the global branch/path history and the branch address. Like the TAGE predictor, ITTAGE uses (partially) tagged components as the PPM-like predictor [2]. It relies on (partial) match to select the predicted target of an indirect jump. TAGE also uses GEometric history length as the O-GEHL predictor [3], i.e. , the set of used global history lengths forms a geometric series. This allows to efficiently capture correlation on recent branch outcomes as well as on very old branches. Due to the huge storage budget available for the ChampionShip, we propose an ITTAGE predictor featuring 16 prediction tables. On the distributed set of traces, using a path history vector recording only information from indirect jumps and calls was found to be (slightly) more efficient than using a path/branch history vector combining information from all kind of branches.},
   author = {André Seznec},
   title = {A 64-Kbytes ITTAGE indirect branch predictor *},
}
@inproceedings{Kondguli2018,
   abstract = {Prefetching is a central component in most microarchitec-tures. Many different algorithms have been proposed with varying degrees of complexity and effectiveness. There are inherent tradeoffs among various metrics especially when we try to exploit both simpler access patterns and more complex ones simultaneously. Hypothetically, therefore, it is better to have collaboration of sub-components each specialized in exploiting a different access pattern than to have a monolithic design trying to have a similar prefetching scope. In this paper, we present some empirical evidence. We use a few components dedicated for some simple patterns such as canonical strided accesses. We show that a composite prefetcher with these components can significantly out-perform state-of-the-art prefetchers. But more importantly, the composite prefetcher achieves better performance through a more limited prefetching scope while attaining a much higher accuracy. This suggests that the design can be more readily expanded with additional components targeting other patterns.},
   author = {Sushant Kondguli and Michael Huang},
   doi = {10.1109/ISCA.2018.00018},
   isbn = {9781538659847},
   issn = {10636897},
   journal = {Proceedings - International Symposium on Computer Architecture},
   month = {7},
   pages = {83-95},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Division of labor: A more effective approach to prefetching},
   year = {2018},
}
@report{,
   abstract = {This paper presents a new method for branch prediction. The key idea is to use one of the simplest possible neural networks , the perceptron as an alternative to the commonly used two-bit counters. Our predictor achieves increased accuracy by making use of long branch histories, which are possible because the hardware resources for our method scale linearly with the history length. By contrast, other purely dynamic schemes require exponential resources. We describe our design and evaluate it with respect to two well known predictors. We show that for a 4K byte hardware budget our method improves misprediction rates for the SPEC 2000 benchmarks by 10.1% over the gshare predic-tor. Our experiments also provide a better understanding of the situations in which traditional predictors do and do not perform well. Finally, we describe techniques that allow our complex predictor to operate in one cycle.},
   author = {Daniel A Jiménez and Calvin Lin},
   title = {Dynamic Branch Prediction with Perceptrons},
}
@inproceedings{Ramirez2002,
   abstract = {Fetch performance is a very important factor because it effectively limits the overall processor performance. However there is little performance advantage in increasing front-end performance beyond what the back-end can consume. For each processor design, the target is to build the best possible fetch engine for the required performance level. A fetch engine will be better if it provides better performance, but also if it takes fewer resources, requires less chip area, or consumes less power. In this paper we propose a novel fetch architecture based on the execution of long streams of sequential instructions, taking maximum advantage of code layout optimizations. We describe our architecture in detail, and show that it requires less complexity and resources than other high performance fetch architectures like the trace cache, while providing a high fetch performance suitable for wide-issue superscalar processors. Our results show that using our fetch architecture and code layout optimizations obtains 10% higher performance than the EV8 fetch architecture, and 4% higher than the FTB architecture using state-of-the-art branch predictors, while being only 1.5% slower than the trace cache. Even in the absence of code layout optimizations, fetching instruction streams is still 10% faster than the EV8, and only 4% slower than the trace cache. Fetching instruction streams effectively exploits the special characteristics of layout optimized codes to provide a high fetch performance, close to that of a trace cache, but has a much lower cost and complexity, similar to that of a basic block architecture.},
   author = {Alex Ramirez and Oliverio J. Santana and Josep L. Larriba-Pey and Mateo Valero},
   doi = {10.1109/MICRO.2002.1176264},
   isbn = {0769518591},
   issn = {10724451},
   journal = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
   keywords = {Computer architecture,Cost function,Engines,Hip,Process design},
   pages = {371-382},
   publisher = {IEEE Computer Society},
   title = {Fetching instruction streams},
   volume = {2002-January},
   year = {2002},
}
@report{,
   abstract = {Instruction supply is a crucial component of processor performance. Instruction prefetching has been proposed as a mechanism to help reduce instruction cache misses, which in turn can help increase instruction supply to the processor. In this paper we examine a new instruction prefetch architecture called Fetch Directed Prefetching, and compare it to the performance of next-line prefetching and streaming buffers. This architecture uses a decoupled branch predic-tor and instruction cache, so the branch predictor can run ahead of the instruction cache fetch. In addition, we examine marking fetch blocks in the branch predictor that are kicked out of the instruction cache, so branch predicted fetch blocks can be accurately prefetched. Finally, we model the use of idle instruction cache ports to filter prefetch requests, thereby saving bus bandwidth to the L2 cache.},
   author = {Glenn Reinman and Brad Calder and Todd Austin},
   title = {Fetch Directed Instruction Prefetching},
}
@report{,
   title = {Forwardflow: A Scalable Core for Power-Constrained CMPs},
   year = {2010},
}
@inproceedings{Kumar2019,
   abstract = {Exploiting memory level parallelism (MLP) is crucial to hide long memory and last level cache access latencies. While out-of-order (OoO) cores, and techniques building on them, are effective at exploiting MLP, they deliver poor energy efficiency due to their complex hardware and the resulting energy overheads. As energy efficiency becomes the prime design constraint, we investigate low complexity/energy mechanisms to exploit MLP. This work revisits slice-out-of-order (sOoO) cores as an energy efficient alternative to OoO cores for MLP exploitation. These cores construct slices of MLP generating instructions and execute them out-of-order with respect to the rest of instructions. However, the slices and the remaining instructions, by themselves, execute in-order. Though their energy overhead is low compared to full OoO cores, sOoO cores fall considerably behind in terms of MLP extraction. We observe that their dependence-oblivious inorder slice execution causes dependent slices to frequently block MLP generation. To boost MLP generation in sOoO cores, we introduce Freeway, a sOoO core based on a new dependence-aware slice execution policy that tracks dependent slices and keeps them out of the way of MLP extraction. The proposed core incurs minimal area and power overheads, yet approaches the MLP benefits of fully OoO cores. Our evaluation shows that Freeway outperforms the state-of-the-art sOoO core by 12% and is within 7% of the MLP limits of full OoO execution.},
   author = {Rakesh Kumar and Mehdi Alipour and David Black-Schaffer},
   doi = {10.1109/HPCA.2019.00009},
   isbn = {9781728114446},
   journal = {Proceedings - 25th IEEE International Symposium on High Performance Computer Architecture, HPCA 2019},
   keywords = {Energy efficiency,Memory Level Parallelism,Memory wall,Out of order execution},
   month = {3},
   pages = {558-569},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Freeway: Maximizing MLP for slice-out-of-order execution},
   year = {2019},
}
@report{Rohou2015,
   abstract = {Interpreters have been used in many contexts. They provide portability and ease of development at the expense of performance. The literature of the past decade covers analysis of why interpreters are slow, and many software techniques to improve them. A large proportion of these works focuses on the dispatch loop, and in particular on the implementation of the switch statement: typically an indirect branch instruction. Folklore attributes a significant penalty to this branch, due to its high misprediction rate. We revisit this assumption , considering state-of-the-art branch predictors and the three most recent Intel processor generations on current interpreters. Using both hardware counters on Haswell, the latest Intel processor generation, and simulation of the IT-TAGE, we show that the accuracy of indirect branch prediction is no longer critical for interpreters. We further compare the characteristics of these interpreters and analyze why the indirect branch is less important than before.},
   author = {Erven Rohou and Bharath Narasimha Swamy and André Seznec and Erven ROHOU Bharath NARASIMHA SWAMY},
   title = {Bharath Narasimha Swamy, André Seznec. Branch Prediction and the Performance of Interpreters-Don't Trust Folklore},
   url = {https://hal.inria.fr/hal-01100647},
   year = {2015},
}
@report{,
   abstract = {The next stream predictor is an accurate branch predictor that provides stream level sequencing. Every stream prediction contains a full stream of instructions, that is, a sequence of instructions from the target of a taken branch to the next taken branch, potentially containing multiple basic blocks. The long size of instruction streams makes it possible for the stream predictor to provide high fetch bandwidth and to tolerate the prediction table access latency. Therefore, an excellent way for improving the behavior of the next stream predictor is to enlarge instruction streams. In this paper, we provide a comprehensive analysis of dynamic instruction streams, showing that there are several kinds of streams according to the terminating branch type. Consequently, focusing on particular kinds of stream is not a good strategy due to Amdahl's law. We propose the multiple stream predictor, a novel mechanism that deals with all kinds of streams by combining single streams into long virtual streams. We show that our multiple stream predictor is able to tolerate the prediction table access latency without requiring the complexity caused by additional hardware mechanisms like prediction overriding, also reducing the overall branch predictor energy consumption.},
   author = {Oliverio J Santana and Alex Ramirez and Mateo Valero},
   keywords = {access latency,branch prediction,instruc-tion stream,microarchitecture},
   title = {Multiple Stream Prediction},
}
@inproceedings{Khan2020,
   abstract = {Modern data center applications have rapidly expanding instruction footprints that lead to frequent instruction cache misses, increasing cost and degrading data center performance and energy efficiency. Mitigating instruction cache misses is challenging since existing techniques (1) require significant hardware modifications, (2) expect impractical on-chip storage, or (3) prefetch instructions based on inaccurate understanding of program miss behavior. To overcome these limitations, we first investigate the challenges of effective instruction prefetching. We then use insights derived from our investigation to develop I-SPY, a novel profiledriven prefetching technique. I-SPY uses dynamic miss profiles to drive an offline analysis of I-cache miss behavior, which it uses to inform prefetching decisions. Two key techniques underlie ISPY's design: (1) conditional prefetching, which only prefetches instructions if the program context is known to lead to misses, and (2) prefetch coalescing, which merges multiple prefetches of noncontiguous cache lines into a single prefetch instruction. I-SPY exposes these techniques via a family of light-weight hardware code prefetch instructions. We study I-SPY in the context of nine data center applications and show that it provides an average of 15.5% (up to 45.9%) speedup and 95.9% (and up to 98.4%) reduction in instruction cache misses, outperforming the state-of-the-art prefetching technique by 22.5%. We show that I-SPY achieves performance improvements that are on average 90.5% of the performance of an ideal cache with no misses.},
   author = {Tanvir Ahmed Khan and Akshitha Sriraman and Joseph Devietti and Gilles Pokam and Heiner Litz and Baris Kasikci},
   doi = {10.1109/MICRO50266.2020.00024},
   isbn = {9781728173832},
   issn = {10724451},
   journal = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
   keywords = {Frontend stalls,Memory systems,Prefetching},
   month = {10},
   pages = {146-159},
   publisher = {IEEE Computer Society},
   title = {I-SPY: Context-driven conditional instruction prefetching with coalescing},
   volume = {2020-October},
   year = {2020},
}
@report{,
   abstract = {Recent supers calar processors issue four tnstructzons per cycle. These processors are also powered by highly-parallel supers calar cores.},
   author = {Thomas M Conte and Kishore N Menezes and Patrick M Mills and Burzin A Patel},
   title = {Optimization of Instruction Fetch Mechanisms for High Issue Rates},
}
@inproceedings{Oberoi2004,
   author = {P.S. Oberoi and G.S. Sohi},
   doi = {10.1109/isca.2003.1207003},
   month = {3},
   pages = {230-240},
   publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
   title = {Parallelism in the front-end},
   year = {2004},
}
@inproceedings{Lakshminarasimhan2020,
   abstract = {Superscalar out-of-order cores deliver high performance at the costof increased complexity and power budget. In-order cores, in contrast, are less complex and have a smaller power budget, but offerlow performance. A processor architecture should ideally providehigh performance in a power- and cost-efficient manner. Recentlyproposed slice-out-of-order (sOoO) cores identify backward slicesof memory operations which they execute out-of-order with respect to the rest of the dynamic instruction stream for increasedinstruction-level and memory-hierarchy parallelism. Unfortunately,constructing backward slices is imprecise and hardware-inefficient,leaving performance on the table.In this paper, we propose Forward Slice Core (FSC), a novelcore microarchitecture that builds on a stall-on-use in-order coreand extracts more instruction-level and memory-hierarchy parallelism than slice-out-of-order cores. FSC does so by identifying andsteering forward slices (rather than backward slices) to dedicated inorder FIFO queues. Moreover, FSC puts load-consumers that dependon L1 D-cache misses on the side to enable younger independentload-consumers to execute faster. Finally, FSC eliminates the needfor dynamic memory disambiguation by replicating store-addressinstructions across queues. FSC improves performance by 9.7%on average compared to Freeway, the state-of-the-art sOoO core,across the SPEC CPU2017 benchmarks, while incurring reducedhardware complexity and a similar power budget.},
   author = {Kartik Lakshminarasimhan and Ajeya Naithani and Josué Feliu and Lieven Eeckhout},
   doi = {10.1145/3410463.3414629},
   isbn = {9781450380751},
   issn = {1089795X},
   journal = {Parallel Architectures and Compilation Techniques - Conference Proceedings, PACT},
   month = {9},
   pages = {361-372},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {The forward slice core microarchitecture},
   year = {2020},
}
@inproceedings{Eyerman2009,
   abstract = {This paper proposes a cycle accounting architecture for Simultaneous Multithreading (SMT) processors that estimates the execution times for each of the threads had they been executed alone, while they are running simultaneously on the SMT processor. This is done by accounting each cycle to either a base, miss event or waiting cycle component during multi-threaded execution. Single-threaded alone execution time is then estimated as the sum of the base and miss event components; the waiting cycle component represents the lost cycle count due to SMT execution. The cycle accounting architecture incurs reasonable hardware cost (around 1KB of storage) and estimates single-threaded performance with average prediction errors around 7.2% for two-program workloads and 11.7% for four-program workloads. The cycle accounting architecture has several important applications to system software and its interaction with SMT hardware. For one, the estimated single-thread alone execution time provides an accurate picture to system software of the actually consumed processor cycles per thread. The alone execution time instead of the total execution time (timeslice) may make system software scheduling policies more effective. Second, a new class of thread-progress aware SMT fetch policies based on per-thread progress indicators enable system software level priorities to be enforced at the hardware level. Copyright © 2009 ACM.},
   author = {Stijn Eyerman and Lieven Eeckhout},
   doi = {10.1145/1508284.1508260},
   issn = {15232867},
   issue = {3},
   journal = {ACM SIGPLAN Notices},
   keywords = {Cycle accounting,Simultaneous Multithreading (SMT),Thread-progress aware fetch policy},
   pages = {133-144},
   publisher = {Association for Computing Machinery (ACM)},
   title = {Per-Thread cycle accounting in SMT processors},
   volume = {44},
   year = {2009},
}
@article{,
   title = {smb1},
}
@inproceedings{Tarsa2019,
   abstract = {Processors that adapt architecture to workloads at runtime promise compelling performance per watt (PPW) gains, offering one way to mitigate diminishing returns from pipeline scaling. State-of-the-art adaptive CPUs deploy machine learning (ML) models on-chip to optimize hardware by recognizing workload patterns in event counter data. However, despite breakthrough PPW gains, such designs are not yet widely adopted due to the potential for systematic adaptation errors in the field. This paper presents an adaptive CPU based on Intel SkyLake that (1) closes the loop to deployment, and (2) provides a novel mechanism for post-silicon customization. Our CPU performs predictive cluster gating, dynamically setting the issue width of a clustered architecture while clock-gating unused resources. Gating decisions are driven by ML adaptation models that execute on an existing microcontroller, minimizing design complexity and allowing performance characteristics to be adjusted with the ease of a firmware update. Crucially, we show that although adaptation models can suffer from statistical blindspots that risk degrading performance on new workloads, these can be reduced to minimal impact with careful design and training. Our adaptive CPU improves PPW by 31.4% over a comparable non-adaptive CPU on SPEC2017, and exhibits two orders of magnitude fewer Service Level Agreement (SLA) violations than the state-of-the-art. We show how to optimize PPW using models trained to different SLAs or to specific applications, e.g. to improve datacenter hardware in situ. The resulting CPU meets real world deployment criteria for the first time and provides a new means to tailor hardware to individual customers, even as their needs change.},
   author = {Stephen J. Tarsa and Rangeen Basu Roy Chowdhury and Julien Sebot and Gautham Chinya and Jayesh Gaur and Karthik Sankaranarayanan and Chit Kwan Lin and Robert Chappell and Ronak Singhal and Hong Wang},
   doi = {10.1145/3307650.3322267},
   isbn = {9781450366694},
   issn = {10636897},
   journal = {Proceedings - International Symposium on Computer Architecture},
   keywords = {Adaptive hardware,Clustered architectures,Machine learning,Runtime optimization},
   month = {6},
   pages = {14-26},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Post-silicon CPU adaptation made practical using machine learning},
   year = {2019},
}
@article{,
   title = {The_Load_Slice_Core_microarchitecture},
}
@article{Ramirez2005,
   abstract = {This paper explores the use of compiler optimizations which optimize the layout of instructions in memory. The target is to enable the code to make better use of the underlying hardware resources regardless of the specific details of the processor/architecture in order to increase fetch performance. The Software Trace Cache (STC) is a code layout algorithm with a broader target than previous layout optimizations. We target not only an improvement in the instruction cache hit rate, but also an increase in the effective fetch width of the fetch engine. The STC algorithm organizes basic blocks into chains trying to make sequentially executed basic blocks reside in consecutive memory positions, then maps the basic block chains in memory to minimize conflict misses in the important sections of the program. We evaluate and analyze in detail the impact of the STC, and code layout optimizations in general, on the three main aspects of fetch performance: the instruction cache hit rate, the effective fetch width, and the branch prediction accuracy. Our results show that layout optimized codes have some special characteristics that make them more amenable for high-performance instruction fetch: They have a very high rate of not-taken branches and execute long chains of sequential instructions; also, they make very effective use of instruction cache lines, mapping only useful instructions which will execute close in time, increasing both spatial and temporal locality. © 2005 IEEE.},
   author = {Alex Ramirez and Josep L. Larriba-Pey and Mateo Valero},
   doi = {10.1109/TC.2005.13},
   issn = {00189340},
   issue = {1},
   journal = {IEEE Transactions on Computers},
   keywords = {Branch prediction,Compiler optimizations,Instruction fetch,Pipeline processors,Trace cache},
   month = {1},
   pages = {22-35},
   title = {Software trace cache},
   volume = {54},
   year = {2005},
}
@article{,
   title = {1997-ISCA-Complexity-Effective-SuperScalar-Processors},
}
@report{Tyson1997,
   abstract = {As processors continue to exploit more instruction level parallelism, a greater demand is placed o n r educing the eeects of memory access latency. In this paper, we introduce a novel modiication of the processor pipeline called memory renaming. Memory renaming applies register access techniques to load instructions, reducing the eeect of delays caused b y t h e n e ed t o c alculate effective addresses for the load and all preceding stores before the data can be fetched. Memory renaming allows the processor to speculatively fetch values when the producer of the data can be r eliably determined without the need for an eeective address. This work extends previous studies of data value and dependence s p ecula-tion. When memory renaming is added t o t h e p r ocessor pipeline, renaming can be applied to 30% to 50% of all memory references, translating to an overall improvement in execution time of up to 41%. Furthermore, this improvement is seen across all memory segments \{ including the heap segment which has often been diicult to manage eeciently.},
   author = {Gary S Tyson and Todd M Austin},
   journal = {Copyright},
   title = {Published i n t h e P r oceedings of Micro-30},
   year = {1997},
}
@report{,
   abstract = {ÌÌÌ ÌÌØØØØØÓÒ ÓÓ ÓÔÔÓÖØÙÒÒØØØ× ×ÓÖ ÚÐÙÙ ÖÖÙ×× ÓÔØØÑÑÞÞØØÓÒ× Ò ÑÑÑÓÖÝ ÓÔÔÖÖØØÓÒ× ÖÖÕÙÙÖÖ ÖÓØØ ØØØ ØØØÖÖ×××× ×ÒÒ ÚÐÙÙ× ××ÓÓÓÓØØØ ÛÛØØ ØØØ×× ÓÔÔÖÖØØÓÒ× ØÓ ÓÓ ÓÚÚÚÐÐÐÐÐº ÐØØÓÙÙÙ ØØØ ÚÐÙÙ× ×ÖÖ Ø ÝÔÔÔÔÐÐÝ ÝÚÚÚÐÐÐÐÐ ÐÒ ØØØ ÔÔÝ××××Ð ÖÖÖÖ×ØØÖ ¬ÐÐ¸ØØØØÖ ¬ÐÐ¸ØØØØÖ ÔÖÖ××ÒÒÒ ÒÒÓØ ÜÔÐÓÓØØØ Ù×× ÒÓ ÓÖÖÖ×ÔÓÒ¹ ÒÒÒ ÒÒØÛ ÛÛÒ ØØØ Ú ÚÐÙÙ× ×ÒÒ ÒÒÒÖÖ×××× × ÑÑÑÒØØØÒÒÒº ÁÒ ØØØ× ÔÔÔÔÖ Û ÔÖÓÔÓ×× ØØØ ØÜÔÐÐÐÐØ ÑÑÒÒÒÒÑÑÒØ ÓÓ ØØØ ÔÔÝ×¹ Ð ÖÖÖÖ×ØØÖ ¬ÐÐ ÓÒØØÒØ× × ÐÐÚÐ Ò ØØØ ÑÑÑÓÖÝ ÖÖÖ¹ Ý Ý Ý ×ÙÔÔÓÖØØÒÒ ØØØ ÎÐÙÙ ÙÖÖ×× ×××Ó ÓÓÓØØÓÒ ËØÖÙÙØÙÖ´ÎËµº ËØÖÙÙØÙÖ´ÎËµº ÌÌÌ ÌÒØÖÖÖ× ×Ò Î ÎÎË ËË ÚÚ Ú ÓÒÒ¹ØÓ¹ÓÒÒ ÒÓÖÖÖ×ÔÓÒ¹ ÒÒÒ ÛÛØØ Ò ØÖÖÖ× Ò ØØØ ÔÔÝ××××Ð ÖÖÖÖ×ØØÖ ¬ÐÐº ÓÖ ÚÚÐÙÙ ÙÒ ØØØ ÖÖÖÖ×ØØÖ ¬ÐÐ ØØØØ Ø× ×ÒÚÓÐÚ ÚÚ ÚÒ Ò ÐÓÓÓ ÓÖ ×ØÓÖÖ ÓÔÔÖÖØØÓÒ¸ØØØÓÔÔÖÖØØÓÒ¸ØØØ Ø××ÓÓÓÓØØØ ÒÒÓÖÑÑØØÓÒ¸ÒÒÐÙÙÙÒÒÒÒÓÖÑÑØØÓÒ¸ÒÒÐÙÙÙÒÒ ØØØ ÑÑÑ¹ ÓÖÝ ÖÖ××¸ÖÖÖÖ××¸ÖÖ ×ØÓÖÖÖ Ò ØØØ ÓÖÖÖ×ÔÓÒÒÒÒÒ Î ÎÎËÒØÖÝº ËËÚÖÖÐ ÓÔØØÑÑÞÞØØÓÒ ØØ××× ××Ò ÒÒ ÔÔÖÖÓÖÑÑÑ Ù××ÒÒ ØØØ ØÓÑ¹ ÒÒØØÓÒ ÓÓ ÔÔÝ××××Ð ÖÖÖÖ×ØØÖ× ×ÒÒ ÎËº ËÔÔÔÔ¬¬¬ÐÐÝ ÎË ËÒÒÒÐÐ× ÙÒÒ¬¬¬ ¬ÑÔÐÐÑÑÒØØØØÓÒ ÓÓ ØØØ ØÓÐ¹ ÐÓÛÛÒÒ ÓÔØØÑÑÞÞØØÓÒ ØØ××××´´µØØ××××´´µ ËØÓÖ Ö¹ØÓ¹ÐÓ ÓÓ ÓÖÛÛÖÒÒ × ÔÔÖÖÓÖÑÑÑ ÛÛØØÓÙØ ÜÔÐÐÐÐØÐÝ ××ÚÚÒÒ ØØØ ×ØÓÖÖÖ ÚÚÐÙÙ××´´´µÚÚÐÙÙ××´´´µ Ä ÓÓÓ¹ØÓ¹ÐÓ ÓÖÛ ÛÖÖÖÒÒ Ò× ÔÔÖÖÓÖÑÑÑ ÛÛØØÓÙØ ×× ÚÚÒÒ ÐÓÓÓÓÓ ÚÚÐÙÙ× Ò ÖÖÙ×× Ù««ÖÖ´´´´µÙ««ÖÖ´´´´µ ËËÐÐÒØ ×ØÓÖÖ× ÖÖ ÐÐÑÑÒÒØØØ ÛÛØØÓÙØ ××ÚÚÒÒ ÓÖ ÐÓÓÓÓÒÒ ØØØ ÔÖÖÓÖ ÚÐÙÙ ×ØÓÖÖÖ ØÓ ØØØ ××ÑÑ ÖÖ×××××´´ÚµÖÖ×××××´´Úµ ËÛÛØØØØÒÒ ÓÓ Ø× Ò Ä½ × ÑÑÒÒÑÑÞÞÞ ÛÛØØÓÙØ ××ÚÚÒÒ ØØÓÒÒÐ ×ØÓÖÝÝ ÒÒ´ÚµÒÒ´Úµ Ð×× ÑÑÑÓÖÝ ×× ÓÖÖÖÖ ÚÚÓÐÐØØÓÒ× ÖÖ Ö ÚÓÓÓÓÓ ÛÛØØÓÙØ ØÓÐÐÐÒÒ ×ÔÔÔÙÐÐ¹ ØØÚÚÐÝ ÐÓÓÓÓÓ ÚÐÙÙ× ×Ò ØØØ ×ÔÔÔÙÐÐØØØ ÐÓÓÓ× ØØØÐÐº ÇÙÖ ÜÔÔÖÖÑÑÒØ× ÑÓÒ×ØÖÖØØ ØØØØ ÓÙÖ ÑÔÐÐÑÑÒØØØØÓÒ ÓÓ ÒÓÒ¹×ÔÔÔÙÐÐØØÚ ÓÔØØÑÑÞÞØØÓÒ× ×× ××××ÐÝ Ý«««ØØÚ × × Ø Ø Ð Ð Ñ ¹ ÒÒØØ× ÑÑÑÓÖÝ ÖÖÖÖÖÖÒÒÒ× ÙÙ ØÓ ¼±´´´±µ¼±´´´±µ ÓÓ ÐÓÓÓ× Ò ËÈÈÈÈÒØØØ´ËÈÈÈÈÔÔÔµËÈÈÈÈÒØØØ´ËÈÈÈÈÔÔÔµ µÒÒ ¾¾±´¾¾ºº±µ¾¾±´¾¾ºº±µ ÓÓ ×ØÓÖÖ× ×Ò ËÈÈÈÈÒØØØ´ËÈÈÈÈÔÔÔµº ËÈÈÈÈÒØØØ´ËÈÈÈÈÔÔÔµº ÇÒ ÒÒ ÒÚÚÖÖÖÖ Ó ÚÚÖ ÖÖ± ÓÓ ÓÓÓ ÖÖÖÖÖÖÒÒÒ× ×ÖÖ ÐÐÑÑÒÒØØØ ØÙÙ ØÓ ÒÓÒ¹×ÔÔÔÙÐÐØØÚ ÖÖÙ××º ÇÒ ÒÒ ÒÚÚÖÖÖÖ ØØØ Ä½ ×ÛÛØØÒÒ ÒÒØØÚÚØÝ Û × ÖÖÖÙÙÙÙ ÙÝ Ýººº±º},
   title = {Load and Store Reuse Using Register File Contents},
   year = {2001},
}
@report{,
   abstract = {The microarchitecture design of a processor has been increasingly difficult due to the large design space and time-consuming verification flow. Previously, researchers rely on prior knowledge and cycle-accurate simulators to analyze the performance of different microarchitecture designs but lack sufficient discussions on methodologies to strike a good balance between power and performance. This work proposes an automatic framework to explore microarchitecture designs of the RISC-V Berkeley Out-of-Order Machine (BOOM), termed as BOOM-Explorer, achieving a good trade-off on power and performance. Firstly, the framework utilizes an advanced microarchitecture-aware active learning (MicroAL) algorithm to generate a diverse and representative initial design set. Secondly, a Gaussian process model with deep kernel learning functions (DKL-GP) is built to characterize the design space. Thirdly, correlated multi-objective Bayesian optimization is leveraged to explore Pareto-optimal designs. Experimental results show that BOOM-Explorer can search for designs that dominate previous arts and designs developed by senior engineers in terms of power and performance within a much shorter time.},
   author = {Chen Bai and Qi Sun and Jianwang Zhai and Yuzhe Ma and Bei Yu and Martin D F Wong},
   title = {BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework},
}
@report{Seznec2014,
   author = {André Seznec and . Tage-Sc-L Branch Predictors},
   keywords = {()},
   title = {JILP-Championship Branch Prediction},
   url = {http://www.jilp.org/cbp2014/},
   year = {2014},
}
@report{,
   abstract = {Out-of order superscalar microprocessors execute znstructions beyond those stalled by cache misses This mMzznzmzzes the tzme lost due to latency by completing other instructions and initiating subsequent cache refills early. he Mips RlOOOO is a dynamic, super-scalar microprocessor that implements T the 64-bit Mips 4 instruction set architecture. It fetches and decodes four instructions per cycle and dynamically issues them to five fully-pipelined, low-latency execution units. Instructions can be fetched and executed speculatively beyond branches. Instructions graduate in order upon completion. Although execution is out of order, the processor still provides sequential memory consistency and precise exception handling. The RlOOOO is designed for high performance , even in large, real-world applications with poor memory locality. With speculative execution, it calculates memory addresses and initiates cache refills early. Its hierarchical , nonblocking memory system helps hide memory latency with two levels of set-asso-ciative, write-back caches. Figure 1 shows the RlOOOO system configuration, and the RlOOOO box lists its principal features. Out-of-order superscalar processors are inherently complex. To cope with this complexity , the RlOOOO uses a modular design that locates much of the control logic within regular structures, including the active list, register map tables, and instruction queues. Design rationale Memory bandwidth and latency limit the performance of many programs. Because packaging and system costs constrain these resources, the processor must use them efficiently. The RlOOOO implements register mapping and nonblocking caches, which complement each other to overlap cache refill operations. Thus, if an instruction misses in the cache, it musi wait for its operand to be refilled, but other instructions can continue out of order. This increases memory use and reduces effective latency, because refills begin early and up to four refills proceed in parallel while the processor executes other instructions This type of cache design is called "nonblocking," because cache refills do not block subsequent accesses to other cache lines Processors rely on compiler support io optimize instruction sequencing This technique is especially effective for data arrays, such as those used in many floating-point applications For these arrays, a sophisticated compiler can opclmize performance for a spe-clfic cache organization However, compiler optimization is less effective for the scalar values of many integer applications, because the compiler has difficulty predicting which instructions will generate cache misses The RlOOOO design includes complex hardware that dynamically reorders instnic-tion execution based on operand availability This hardware immediately adapts whenever cache misses delay instructions The processor looks ahead up to 32 instructions to find possible parallelism This instruction window is large enough to hide most of the latency for refills from the secondary cache However, it can hide only a fraction of main memory latency, which is typically much longer It is relatively easy to add nonblocking caches to an out-of-order piocessor, because it already contains mechanisms that coordinate dependencies between instructions Implementation We implemented the initial RlOOOO micro processor using 0 35-pm CMOS technology on a 16 64x17 934-mm chip This 298 mmz chip contains 6 8 million transistois, including 4 4 million in its primary cache arrays We implemented data paths and time-critical control logic in full custom design, making wide use of dynamic and latch-based logic We synthesized the less critical circuits using static register-based logic 28 IEEEMicro 0272-1732/96/$5.00 0 1996 IEEE Authorized licensed use limited to: University of Wisconsin. Downloaded on January 13, 2009 at 16:34 from IEEE Xplore. Restrictions apply.},
   author = {Kenneth C Yeager},
   title = {THE MIPS RIO000 SUPERSCALAR MICROPROCESSOR},
}
@article{,
   title = {Bit-level_Perceptron_Prediction_for_Indirect_Branches},
}
@report{,
   isbn = {02721732/07},
   title = {FOR COMPUTER DESIGNERS, UNDERSTANDING THE CHARACTERISTICS OF WORKLOADS RUNNING ON CURRENT AND FUTURE COMPUTER SYSTEMS IS OF UTMOST IMPORTANCE DURING MICROPROCESSOR DESIGN. A MICROARCHITECTURE-INDEPENDENT METHOD ENSURES AN ACCURATE CHARACTERIZATION OF INHERENT PROGRAM BEHAVIOR AND AVOIDS THE WEAKNESSES OF MICROARCHITECTURE-DEPENDENT METRICS},
   url = {http://www.eembc.org},
}
@article{,
   title = {tage},
}
@article{Ishii2020,
   abstract = {Instruction prefetching can play a pivotal role in improving the performance of workloads with large instruction footprints and frequent, costly frontend stalls. In particular, Fetch Directed Prefetching (FDP) is an effective technique to mitigate frontend stalls since it leverages existing branch prediction resources in a processor and incurs very little hardware overhead. Modern processors have been trending towards provisioning more frontend resources, and this bodes well for FDP as it requires these resources to be effective. However, recent academic research has been using outdated and less than optimal frontend baselines that employ smaller structures, which may result in misleading outcomes. In this letter, we present a detailed FDP microarchitecture and evaluate two improvements, better branch history management and post-fetch correction. We believe that our FDP-based frontend design can serve as a new reference baseline for instruction prefetching research to bridge the gap between academia and industry.},
   author = {Yasuo Ishii and Jaekyu Lee and Krishnendra Nathella and Dam Sunwoo},
   doi = {10.1109/LCA.2020.3035068},
   issn = {15566064},
   issue = {2},
   journal = {IEEE Computer Architecture Letters},
   keywords = {Instruction prefetching,branch predictor},
   month = {7},
   pages = {147-150},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Rebasing Instruction Prefetching: An Industry Perspective},
   volume = {19},
   year = {2020},
}
@report{,
   abstract = {Modem architecture research relies heavily on detailed pipeline simulation. Simulating the full execution of an industry standard benchmark can take weeks to months to complete. To overcome this problem researchers choose a very small portion of a program's execution to evaluate their results , rather than simulating the entire program. In this paper we propose Basic Block Distribution Analysis as an automated approach for finding these small portions of the program to simulate that are representative of the entire program's execution. This approach is based upon using projiles of a program's code structure (basic blocks) to uniquely identifji different phases of execution in the program. We show that the periodicity of the basic block frequency profile rejects the periodicity of detailed simulation across several different architectural metrics (e.g., IPC, branch miss rate, cache miss rate, value misprediction, address misprediction, and reorder buffer occupancy). Since basic block frequencies can be collected using very fast profiling tools, our approach provides a practical technique for finding the periodicity and simulation points in applications.},
   author = {Timothy Sherwood and Erez Perelman and Brad Calder},
   title = {Basic Block Distribution Analysis to Find Periodic Behavior and Simulation Points in Applications},
}
@article{Reinman2001,
   abstract = {In the pursuit of instruction-level parallelism, significant demands are placed on a processor's instruction delivery mechanism. Delivering the performance necessary to meet future processor execution targets requires that the performance of the instruction delivery mechanism scale with the execution core. Attaining these targets is a challenging task due to I-cache misses, branch mispredictions, and taken branches in the instruction stream. To counter these challenges, we present a fetch architecture that decouples the branch predictor from the instruction fetch unit. A Fetch Target Queue (FTQ) is inserted between the branch predictor and instruction cache. This allows the branch predictor to run far in advance of the address currently being fetched by the cache. The decoupling enables a number of architecture optimizations, including multilevel branch predictor design, fetch-directed instruction prefetching, and easier pipelining of the instruction cache. For the multilevel predictor, we show that it performs better than single-level predictor, even when ignoring the effects of cycle-timing issues. We also examine the performance of fetch-directed instruction prefetching using a multilevel branch predictor and show that an average 19 percent speedup is achieved. In addition, we examine pipelining the instruction cache to achieve a faster cycle time for the processor pipeline and show that pipelining provides an average 27 percent speedup over not pipelining the instruction cache for the programs examined.},
   author = {Glenn Reinman and Brad Calder and Todd Austin},
   doi = {10.1109/12.919279},
   issn = {00189340},
   issue = {4},
   journal = {IEEE Transactions on Computers},
   keywords = {Branch prediction,Decoupled architectures,Fetch architectures,Instruction prefetching},
   month = {4},
   pages = {338-355},
   title = {Optimizations enabled by a decoupled front-end architecture},
   volume = {50},
   year = {2001},
}
@inproceedings{Soundararajan2021,
   abstract = {Due to large instruction footprints, contemporary data center applications suffer from frequent frontend stalls. Despite being a significant contributor to these stalls, the Branch Target Buffer (BTB) has received less attention compared to other frontend structures such as the instruction cache. While prior works have looked at enhancing the BTB through more efficient replacement policies and prefetching policies, a thorough analysis into optimizing the BTB's storage efficiency is missing. In this work, we analyze BTB accesses for a large number (100+) of frontend bound applications to understand their branch target characteristics. This analysis, provides three significant observations about the nature of branch targets: (1) a significant number of branch instructions have the same branch target, (2) a significant number of branch targets share the same page address, and (3) a significant percentage of branch instructions and their targets are located on the same page. Furthermore, we observe that while applications' address spaces are sparsely populated, they exhibit spatial locality within and across pages. We refer to these multi-page addresses as regions and we show that applications traverse a significantly smaller number of regions than pages. Based on these insights, we propose PDede, an efficient re-design of the BTB micro-architecture that improves storage efficiency by removing redundancy among branches and their targets. PDede introduces three techniques, (a) BTB Partitioning, (b) Branch Target Deduplication, and (c) Delta Branch Target Encoding to reduce BTB miss induced frontend stalls. We evaluate PDede across 100+ applications, spanning several usage scenarios, and show that it provides an average 14.4% (up to 76%) IPC speedup by reducing BTB misses by 54.7% on average (and up to 99.8%).},
   author = {Niranjan Soundararajan and Peter Braun and Tanvir Ahmed Khan and Baris Kasikci and Heiner Litz and Sreenivas Subramoney},
   doi = {10.1145/3466752.3480046},
   isbn = {9781450385572},
   issn = {10724451},
   journal = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
   keywords = {Branch Target Buffer,Performance,Superscalar cores},
   month = {10},
   pages = {779-791},
   publisher = {IEEE Computer Society},
   title = {PDede: Partitioned, deduplicated, delta branch target buffer},
   year = {2021},
}
@article{Kim2009,
   abstract = {Indirect branches have become increasingly common in modular programs written in modern object-oriented languages and virtual-machine-based runtime systems. Unfortunately, the prediction accuracy of indirect branches has not improved as much as that of conditional branches. Furthermore, previously proposed indirect branch predictors usually require a significant amount of extra hardware storage and complexity, which makes them less attractive to implement. This paper proposes a new technique for handling indirect branches, called Virtual Program Counter (VPC) prediction. The key idea of VPC prediction is to use the existing conditional branch prediction hardware to predict indirect branch targets, avoiding the need for a separate storage structure. Our comprehensive evaluation shows that VPC prediction improves average performance by 26.7 percent and reduces average energy consumption by 19 percent compared to a commonly used branch target buffer based predictor on 12 indirect branch intensive C/C\{++\} applications. Moreover, VPC prediction improves the average performance of the full set of object-oriented Java DaCapo applications by 21.9 percent, while reducing their average energy consumption by 22 percent. We show that VPC prediction can be used with any existing conditional branch prediction mechanism and that the accuracy of VPC prediction improves when a more accurate conditional branch predictor is used. © 2009 IEEE.},
   author = {Hyesoon Kim and Jose A. Joao and Onur Mutlu and Chang Joo Lee and Yale N. Patt and Robert Cohn},
   doi = {10.1109/TC.2008.227},
   issn = {00189340},
   issue = {9},
   journal = {IEEE Transactions on Computers},
   keywords = {Devirtualization,Indirect branch prediction,Java,Object-oriented languages,Virtual functions},
   pages = {1153-1170},
   title = {Virtual program counter (VPC) prediction: Very low cost indirect branch prediction using conditional branch prediction hardware},
   volume = {58},
   year = {2009},
}
@report{,
   abstract = {The memory wall has motivated many enhancements to cache management policies aimed at reducing misses. Cache compression has been proposed to increase effective cache capacity, which potentially reduces capacity and conflict misses. However, complexity in cache compression implementations could increase cache power and access latency. On the other hand, advanced cache replacement mechanisms use heuristics to reduce misses, leading to significant performance gains. Both cache compression and replacement policies should collaborate to improve performance. In this paper, we demonstrate that cache compression and replacement policies can interact negatively. In many workloads, performance gains from replacement policies are lost due to the need to alter the replacement policy to accommodate compression. This leads to sub-optimal replacement policies that could lose performance compared to an uncompressed cache. We introduce a novel, opportunistic cache compression mechanism, Base-Victim, based on an efficient cache design. Our compression architecture improves performance on top of advanced cache replacement policies, and guarantees a hit rate at least as high as that of an uncompressed cache. For cache-sensitive applications, Base-Victim achieves an average 7.3% performance gain for single-threaded workloads, and 8.7% gain for four-thread multi-program workload mixes.},
   author = {Jayesh Gaur and Alaa R Alameldeen and Sreenivas Subramoney},
   keywords = {cache compression,cache replacement policies},
   title = {Base-Victim Compression: An Opportunistic Cache Compression Architecture},
}
@article{Santana2007,
   abstract = {The stream fetch engine is a high-performance fetch architecture based on the concept of instruction stream. We call stream to a sequence of instructions from the target of a taken branch to the next taken branch, potentially containing multiple basic blocks. The long size of instruction streams makes it possible for the stream fetch enine to provide high fetch bandwidth and to hide the branch predictor access latency, leading to performance results close to a trace cache at lower implementation cost and complexity. Therefore, enlarging instruction streams is an excellent way for improving the stream fetch engine. In this paper, we present several hardware and software mechanisms focused on enlarging those streams that finalize at particular branch types. However, our results point out that focusing on particular branch types is not a good strategy due to Amdahl's law. Consequently, we propose the multiple stream predictor, a novel mechanism that deals with all branch types by combining single streams into long virtual streams. This proposal tolerates the prediction table access latency without requiring the complexity caused by additional hardware mechanisms like prediction overriding. Moreover, it provides high performance results, which are comparable to state-of-the-art fetch architectures, but with a simpler design that consumes less energy. © 2007 IEEE.},
   author = {Oliverio J. Santana and Alex Ramirez and Mateo Valero},
   doi = {10.1109/TC.2007.70742},
   issn = {00189340},
   issue = {10},
   journal = {IEEE Transactions on Computers},
   keywords = {Access latency,Branch prediction,Code optimization,Instruction fetch,Superscalar processor design},
   month = {10},
   pages = {1342-1357},
   title = {Enlarging instruction streams},
   volume = {56},
   year = {2007},
}
@book{Carro2011,
   abstract = {Title from The ACM Digital Library.},
   author = {Luigi. Carro and ACM Digital Library. and ACM Special Interest Group on Microarchitectural Research and Processing.},
   isbn = {9781450310536},
   pages = {519},
   publisher = {ACM},
   title = {Proceedings of the 44th Annual IEEEACM International Symposium on Microarchitecture.},
   year = {2011},
}
@book{,
   abstract = {"IEEE Computer Society Order Number P2270; ACM Order Number 415054"--Title page verso},
   author = {IEEE Computer Society. Technical Committee on Computer Architecture. and Sigarch.},
   isbn = {076952270X},
   pages = {557},
   publisher = {IEEE Computer Society},
   title = {Proceedings, 32nd International Symposium on Computer Architecture : Madison, Wisconsin, June 4-8, 2005},
   year = {2005},
}
@book{,
   abstract = {"IEEE Computer Society Order Number P2270; ACM Order Number 415054"--Title page verso},
   author = {IEEE Computer Society. Technical Committee on Computer Architecture. and Sigarch.},
   isbn = {076952270X},
   pages = {557},
   publisher = {IEEE Computer Society},
   title = {Proceedings, 32nd International Symposium on Computer Architecture : Madison, Wisconsin, June 4-8, 2005},
   year = {2005},
}
@inproceedings{Perais2019,
   abstract = {Branch prediction (i.e., the generation of fetch addresses) and instruction cache accesses need not be tightly coupled. As the instruction fetch stage stalls because of an ICache miss or back-pressure, the branch predictor may run ahead and generate future fetch addresses that can be used for different optimizations, such as instruction prefetching but more importantly hiding taken branch fetch bubbles. This approach is used in many commercially available highperformance design. However, decoupling branch prediction from instruction retrieval has several drawbacks. First, it can increase the pipeline depth, leading to more expensive pipeline flushes. Second, it requires a large Branch Target Buffer (BTB) to store branch targets, allowing the branch predictor to follow taken branches without decoding instruction bytes. Missing the BTB will also cause additional bubbles. In some classes of workloads, those drawbacks may significantly offset the benefits of decoupling. In this paper, we present ELastic Fetching (ELF), a hybrid mechanism that decouples branch prediction from instruction retrieval while minimizing additional bubbles on pipeline flushes and BTB misses. We present two different implementations that trade off complexity for additional performance. Both variants outperform a baseline decoupled fetcher design by up to 3.7% and 5.2%, respectively.},
   author = {Arthur Perais and Rami Sheikh and Luke Yen and Michael McIlvaine and Robert D. Clancy},
   doi = {10.1109/HPCA.2019.00059},
   isbn = {9781728114446},
   journal = {Proceedings - 25th IEEE International Symposium on High Performance Computer Architecture, HPCA 2019},
   keywords = {Decoupled fetcher,Instruction fetch,Microarchitecture},
   month = {3},
   pages = {478-490},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Elastic instruction fetching},
   year = {2019},
}
